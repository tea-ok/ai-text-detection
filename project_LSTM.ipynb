{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AI Text Cassification with PyTorch + LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Taavi Kalaluka, 2024**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The idea for this project came from a deep interest in AI and its effect on society. Ever since the advent of ChatGPT, I've been wondering how it will impact our society. I have a little sister in 7th grade and I thought about how different school must be for her compared to how it was for me, since ChatGPT excels at simple essays. Surely many students in middle school would be tempted to use ChatGPT to write their essays for English class, when back in the days we had to do everything with our own brains.\n",
    "\n",
    "Then I remembered hearing about an AI detection tool on Instagram, where an American college student had created a system for identifying AI text. I was sceptical at how well such a tool would work. How could you possibly detect AI in text? Human text is so complex, and humans have very different writing styles. I hypothesized that he must have used AI to detect AI, fighting fire with fire. I was motivated to try something similar, to see how well it would work out.\n",
    "\n",
    "I've been tinkering with AI for quite a long time now, having completed Stanford Online's Machine Learning Specialization in early 2023 and messed around with custom versions of different LLMs in my free time. I initially thought that I would have to use a pre-trained language model for this project, and train a custom version to detect AI. However, I also figured that it would be an excellent learning experience to implement my own model from scratch, even though the results might not be as good.\n",
    "\n",
    "For this project, I decided to use PyTorch since we used Tensorflow in this course and I thought it would be a good opportunity to use another deep learning framework. Initially, it was quite complicated to make the switch, as PyTorch requires you to do many things manually which Tensorflow does automatically out of the box (thanks to Keras for making it so easy). Even though PyTorch is a lot more code, it has the advantage of allowing for more flexbility and customization. Overall, I'm a big fan of PyTorch!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pandas for data loading\n",
    "import pandas as pd\n",
    "\n",
    "# Tqdm for \n",
    "from tqdm import tqdm\n",
    "\n",
    "# Seaborn and matplotlib for visualization\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# PyTorch for model building\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import random_split\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "\n",
    "# BERT Tokenizer from the transformers library\n",
    "from transformers import BertTokenizer\n",
    "\n",
    "# Scikit-learn for model evaluation\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data loading and initial analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I used Google Colab for running this notebook, because of the free T4 GPUs they allow you to use. This made training significantly faster, and allowed me to test many different versions of the model without frying my computer. However, for everything apart from the training of the model I still used my computer, and that's why I have two different ways of loading the data below, depending on whether I'm using my computer or Colab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Colab stuff\n",
    "\n",
    "# from google.colab import drive\n",
    "\n",
    "# drive.mount('/content/drive')\n",
    "\n",
    "# df = pd.read_csv('/content/drive/My Drive/AI classification/data/AI_Human.csv')\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows: 487235\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>generated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Cars. Cars have been around since they became ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Transportation is a large necessity in most co...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"America's love affair with it's vehicles seem...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>How often do you ride in a car? Do you drive a...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Cars are a wonderful thing. They are perhaps o...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  generated\n",
       "0  Cars. Cars have been around since they became ...        0.0\n",
       "1  Transportation is a large necessity in most co...        0.0\n",
       "2  \"America's love affair with it's vehicles seem...        0.0\n",
       "3  How often do you ride in a car? Do you drive a...        0.0\n",
       "4  Cars are a wonderful thing. They are perhaps o...        0.0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/AI_Human.csv')\n",
    "print(f'Number of rows: {len(df)}')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset contains 487,235 rows, where each row is an example. The column `text` contains the essay and the column `generated` tells us whether it is human or AI text:\n",
    "\n",
    "- 0.0 = human\n",
    "- 1.0 = AI\n",
    "\n",
    "The `.csv` file is 1.11 GB in size, which is quite large for a file containing text. This is why I decided to use a smaller subset of the data for this project, containing only 10,000 examples. Using the whole dataset would take an incredibly long time to train on the free Colab GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows in data subset: 10000\n"
     ]
    }
   ],
   "source": [
    "# Generating a subset of the dataset with 10,000 rows\n",
    "df_zero = df[df['generated'] == 0]\n",
    "df_one = df[df['generated'] == 1]\n",
    "\n",
    "# Equal number of positive and negative casses\n",
    "df_zero_sampled = df_zero.sample(5000, random_state=1)\n",
    "df_one_sampled = df_one.sample(5000, random_state=1)\n",
    "\n",
    "df = pd.concat([df_zero_sampled, df_one_sampled])\n",
    "df.reset_index(inplace=True)\n",
    "print(f'Number of rows in data subset: {len(df)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I opted for the BERT tokenizer provided by the Hugging Face's Transformers library here, due to its many advantages:\n",
    "\n",
    "- **WordPiece Tokenization**: BERT uses WordPiece tokenization. This method breaks words into subwords, which can help models handle unseen words or rare words. For example, the word \"unhappiness\" might be tokenized into \"un\", \"##happy\", and \"##ness\".\n",
    "\n",
    "- **Handling of Out-of-Vocabulary Words**: Thanks to WordPiece tokenization, BERT can handle out-of-vocabulary words, breaking them down into subwords that it has seen during training.\n",
    "\n",
    "- **Multilingual Support**: The BERT tokenizer has multilingual support, meaning it can handle text in many different languages. The text in this project is in English, but it would be interesting to try it on other languages as well.\n",
    "\n",
    "- **Efficiency**: The BERT tokenizer is efficient and can quickly tokenize large amounts of text.\n",
    "\n",
    "- **Easy to Use**: With the Transformers library, using the BERT tokenizer is very simple, it can be done by instatiating a `BertTokenizer` class with the name of the pre-trained model you want to use.\n",
    "\n",
    "Let's take a look at the dataset, by tokenizing it with `bert-base-uncased` and displaying distribution of tokens:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum number of tokens in a text: 512\n",
      "95th percentile of number of tokens in a text: 512.0\n"
     ]
    }
   ],
   "source": [
    "# Initializing the tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Tokenizing the text and calculating the number of tokens in each text\n",
    "df['num_tokens'] = df['text'].apply(lambda x: len(tokenizer.encode(x, truncation=True)))\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.hist(df['num_tokens'], bins=50)\n",
    "plt.xlabel('Number of Tokens')\n",
    "plt.ylabel('Number of Texts')\n",
    "plt.title('Distribution of Number of Tokens in Texts')\n",
    "plt.show()\n",
    "\n",
    "print(f\"Maximum number of tokens in a text: {df['num_tokens'].max()}\")\n",
    "print(f\"95th percentile of number of tokens in a text: {df['num_tokens'].quantile(0.95)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this histogram, it is evident that the vast majority of essays are around 512 tokens in length. The reason for such a massive spike around this value is most likely due to the maximum number of tokens allowed with the BERT tokenizer, which is 512. So, many of the essays were longer than 512 tokens, but they were truncated to 512 tokens. This should be fine, and means that the training of the model will be more efficient than if we used other tokenizers and more tokens."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating The Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, I have defined a custom `TextDataset` class, which inherits from PyTorch's `Dataset` class. An instance of the object takes in the following parameters:\n",
    "\n",
    "1. `dataframe` - The dataframe from which the dataset should be created\n",
    "2. `tokenizer` - The tokenizer used for the dataset\n",
    "3. `max_len` - The maximum length of each data input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextDataset(Dataset):\n",
    "    def __init__(self, dataframe, tokenizer, max_len):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.data = dataframe\n",
    "        self.text = dataframe.text\n",
    "        self.targets = dataframe.generated\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.text)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        text = str(self.text[index])\n",
    "        text = \" \".join(text.split())\n",
    "\n",
    "        inputs = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            None,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_token_type_ids=True\n",
    "        )\n",
    "        ids = inputs['input_ids']\n",
    "\n",
    "        # Calculating the length of the sequence before padding\n",
    "        text_length = len([token for token in ids if token != self.tokenizer.pad_token_id])\n",
    "\n",
    "        return {\n",
    "            'ids': torch.tensor(ids, dtype=torch.long),\n",
    "            'targets': torch.tensor(self.targets[index], dtype=torch.float),\n",
    "            'text_lengths': torch.tensor(text_length, dtype=torch.long)\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`__getitem__` will be called with each index in the dataframe later on by the data loaders, returning the following dictionary for each call:\n",
    "\n",
    "- `ids` - The text (essay) as a tensor\n",
    "- `targets` - The target (human or AI, 0 or 1) as a tensor\n",
    "- `text_lengths` - The length of the essay in tokens, excluding padding\n",
    "\n",
    "Below, I've set the `max_len` variable to 512, as that was the number of tokens for most essays in the data. Essays longer than this will be truncated to 512 tokens, and essays longer than this will be padded to 512, ensuring that all sequences passed to the model are of the same length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 512\n",
    "\n",
    "# Create the Dataset\n",
    "dataset = TextDataset(df, tokenizer, max_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I wrote a function to create the data loaders, so that train/test/validation splits can be easily modified later on. I currently have them set to 80% for training, 10% for validation and 10% for testing, along with a batch size of 128.\n",
    "\n",
    "The function returns data loaders for each of these using the specified parameters, taking in a `TextDataset` object created earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data_loaders(dataset, train_prop=0.8, val_prop=0.1, test_prop=0.1, batch_size=128):\n",
    "    train_len = int(train_prop * len(dataset))\n",
    "    val_len = int(val_prop * len(dataset))\n",
    "    test_len = int(test_prop * len(dataset))\n",
    "\n",
    "    train_set, val_set, test_set = random_split(dataset, [train_len, val_len, test_len])\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = torch.utils.data.DataLoader(val_set, batch_size=batch_size, shuffle=False)\n",
    "    test_loader = torch.utils.data.DataLoader(test_set, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    return train_loader, val_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, val_loader, test_loader = create_data_loaders(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building The Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This part was rather tricky, as PyTorch requires you to implement the `forward` function yourself. However, with the help of some blog posts I finally figured it out.\n",
    "\n",
    "The class has the following components:\n",
    "\n",
    "1. **Embedding Layer (`self.embedding`)**: This layer transforms the input words (represented as numbers) into dense vectors of fixed size. The `vocab_size` parameter is the number of unique words in the vocabulary, and `embedding_dim` is the size of the embedding vectors.\n",
    "\n",
    "2. **LSTM Layer (`self.lstm`)**: This is the main component of the model. It's a type of recurrent neural network (RNN) that can learn long-term dependencies between words in the text. The `input_size` is the size of the input to each LSTM cell (which is the size of the embedding), and `dimension` is the size of the hidden state and cell state of the LSTM.\n",
    "\n",
    "3. **Dropout Layer (`self.drop`)**: This layer randomly sets a fraction `p` of the input units to 0 at each update during training time, which helps prevent overfitting.\n",
    "\n",
    "4. **Linear Layer (`self.fc`)**: This layer is a linear transformation (y = Ax + b) that is applied to the output of the LSTM layer. It reduces the dimension from `dimension` to 1. The output of this layer is then passed through a sigmoid function to output a probability.\n",
    "\n",
    "In the `forward` method, the input text is passed through each of these layers in turn. The LSTM layer uses packed sequences for efficiency (`pack_padded_sequence`), and the output from the LSTM is unpacked and the final hidden state is extracted and passed through the dropout and linear layers. The output is then squeezed to remove any extra dimensions and a sigmoid function is applied to get the final output probability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMClassifier(nn.Module):\n",
    "\n",
    "    def __init__(self, vocab_size, embedding_dim, dimension):\n",
    "        super(LSTMClassifier, self).__init__()\n",
    "\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.dimension = dimension\n",
    "        self.lstm = nn.LSTM(input_size=embedding_dim,\n",
    "                            hidden_size=dimension,\n",
    "                            num_layers=1,\n",
    "                            batch_first=True)\n",
    "        \n",
    "        self.drop = nn.Dropout(p=0.5)\n",
    "\n",
    "        self.fc = nn.Linear(dimension, 1)\n",
    "\n",
    "    def forward(self, text, text_len):\n",
    "\n",
    "        text_emb = self.embedding(text)\n",
    "\n",
    "        packed_input = pack_padded_sequence(text_emb, text_len, batch_first=True)\n",
    "        packed_output, _ = self.lstm(packed_input)\n",
    "        output, _ = pad_packed_sequence(packed_output, batch_first=True)\n",
    "\n",
    "        out_forward = output[range(len(output)), text_len - 1, :self.dimension]\n",
    "        text_fea = self.drop(out_forward)\n",
    "\n",
    "        text_fea = self.fc(text_fea)\n",
    "        text_fea = torch.squeeze(text_fea, 1)\n",
    "        text_out = torch.sigmoid(text_fea)\n",
    "\n",
    "        return text_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating the mode, with a `vocab_size` equal to the length of the tokenizer's vocabulary, a `dimension` of 32, and an `embedding_dim` of 100.\n",
    "\n",
    "1. `embedding_dim` of 100: This refers to the size of the vector space in which words will be embedded. It defines the size of the output vectors from this layer for each word. For example, it could be 32 or 100 or 256, etc. This is the size of the dense vector that each word will be transformed into. In other words, each input word will be represented by a vector of size 100.\n",
    "\n",
    "2. `dimension` of 32: This is the dimensionality of the output space of LSTM layer. In other words, it is the number of nodes in the hidden layer of the LSTM. This means that the LSTM will output vectors of size 32. This is often called the number of \"hidden units\" or \"LSTM units\". This is a hyperparameter you can tune, and different values can result in different model performance.\n",
    "\n",
    "3. `vocab_size` of `len(tokenizer.vocab)`: This is a parameter that specifies the number of unique words in the vocabulary. In the context of this model, it's used to define the size of the embedding layer, which will learn a vector representation for each word in the vocabulary.\n",
    "\n",
    "    `len(tokenizer.vocab)` gives the number of unique words that the tokenizer can recognize. By setting `vocab_size` to that, we're ensuring that the embedding layer can learn a unique vector representation for each word in the tokenizer's vocabulary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size: 30522\n"
     ]
    }
   ],
   "source": [
    "# Defining model hyperparameters\n",
    "vocab_size = len(tokenizer.vocab)\n",
    "dimension = 32\n",
    "embedding_dim = 100\n",
    "\n",
    "print(f'Vocab size: {vocab_size}')\n",
    "model = LSTMClassifier(vocab_size, embedding_dim, dimension)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Taking a look at the model summary. Unfortunately, we can't do it in a nice visual way as we can with Tensorflow, but we can still inspect the architecture:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Summary:\n",
      "--------------------\n",
      "embedding.weight\t[30522, 100]\t3052200\n",
      "lstm.weight_ih_l0\t[128, 100]\t12800\n",
      "lstm.weight_hh_l0\t[128, 32]\t4096\n",
      "lstm.bias_ih_l0\t[128]\t128\n",
      "lstm.bias_hh_l0\t[128]\t128\n",
      "fc.weight\t[1, 32]\t32\n",
      "fc.bias\t[1]\t1\n",
      "--------------------\n",
      "Total Params:3069385\n"
     ]
    }
   ],
   "source": [
    "def print_model_summary(model):\n",
    "    print('Model Summary:')\n",
    "    print('--------------------')\n",
    "    total_params = 0\n",
    "    for name, parameter in model.named_parameters():\n",
    "        param = parameter.numel()\n",
    "        total_params+=param\n",
    "        print(f'{name}\\t{str(list(parameter.shape))}\\t{param}')\n",
    "    print('--------------------')\n",
    "    print(f'Total Params:{total_params}')\n",
    "\n",
    "print_model_summary(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Something important to note here is that in PyTorch's LSTM implementation, an LSTM layer's weights and biases are organized into \"gates\". Each LSTM unit has 4 gates (input, forget, cell and output), so the total number of weight and bias parameters for each LSTM unit is 4 times the number of units https://pytorch.org/docs/stable/generated/torch.nn.LSTM.html.\n",
    "\n",
    "So, for this model:\n",
    "\n",
    "- `lstm.weight_ih_l0 [128, 100]` and `lstm.bias_ih_l0 [128]` are the weights and biases for the input-to-hidden connections. The first dimension is 128 because there are 32 LSTM units * 4 gates per unit\n",
    "\n",
    "- `lstm.weight_hh_l0 [128, 32]` and `lstm.bias_hh_l0 [128]` are the weights and biases for the hidden-to-hidden connections. Here as well, the first dimension is 128 because there are 32 LSTM units * 4 gates per unit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training The Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyTorch also requires you to write your own training and testing loops. I decided to organize these into their own functions.\n",
    "\n",
    "The `train_model` function below takes as parameters `epochs`, `train_loader`, `val_loader`, `model`, `criterion`, `optimizer` and `device`.\n",
    "\n",
    "- `epochs` - The number of training iterations\n",
    "- `train_loader` - The data loader with the training data\n",
    "- `val_loader` - The data loader with the validation data\n",
    "- `model` - The model being trained\n",
    "- `criterion` - The loss function to use\n",
    "- `optimizer` - The optimizer to use\n",
    "- `device` - The device on which to train on, ideally GPU but CPU if that's not available\n",
    "\n",
    "The function keeps track of the losses during training, both train and validation. Additionally, the validation accuracies are also tracked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train function\n",
    "\n",
    "def train_model(epochs, train_loader, val_loader, model, criterion, optimizer, device):\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    val_accuracies = []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        # Performing training on all batches for an epoch\n",
    "        model.train() # Setting model to training mode\n",
    "        # Initializing progress bar\n",
    "        train_progress_bar = tqdm(train_loader, desc=f'Epoch {epoch + 1}/{epochs}', unit='batch')\n",
    "\n",
    "        # Initializing loss for this epoch\n",
    "        epoch_train_loss = 0\n",
    "        for batch in train_progress_bar:\n",
    "            # Zeroing the gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Sorting the lengths of text in descending order and getting the sorted indices\n",
    "            text_lengths, sorted_idx = batch['text_lengths'].sort(descending=True)\n",
    "            # Using the sorted indices to rearrange the ids and targets\n",
    "            ids = batch['ids'][sorted_idx]\n",
    "            targets = batch['targets'][sorted_idx]\n",
    "\n",
    "            # Moving ids, text_lengths, and targets to the specified device\n",
    "            ids = ids.to(device)\n",
    "            text_lengths = text_lengths.to(device)\n",
    "            targets = targets.to(device)\n",
    "\n",
    "            # Forward pass: computing predictions y by passing x (ids and text lengths) to the model\n",
    "            predictions = model(ids, text_lengths)\n",
    "            # Computing loss with the specified criterion\n",
    "            loss = criterion(predictions, targets)\n",
    "\n",
    "            # Backward pass: computing gradient of the loss with respect to model parameters\n",
    "            loss.backward()\n",
    "            # Performing a single optimization step (parameter update)\n",
    "            optimizer.step()\n",
    "\n",
    "            # Updating training loss for epoch\n",
    "            epoch_train_loss += loss.item()\n",
    "            # Updating progress bar\n",
    "            train_progress_bar.set_postfix({'training_loss': '{:.3f}'.format(loss.item())})\n",
    "\n",
    "        # Appending average training loss for epoch\n",
    "        train_losses.append(epoch_train_loss / len(train_loader))\n",
    "\n",
    "        # Performing validation at the end of each epoch\n",
    "        model.eval() # Setting the model to evaluation mode\n",
    "        with torch.no_grad(): # No gradient during validation\n",
    "            total_loss, total_correct, total_labels = 0, 0, 0\n",
    "            for batch in val_loader:\n",
    "                text_lengths, sorted_idx = batch['text_lengths'].sort(descending=True)\n",
    "                ids = batch['ids'][sorted_idx]\n",
    "                targets = batch['targets'][sorted_idx]\n",
    "\n",
    "                ids = ids.to(device)\n",
    "                text_lengths = text_lengths.to(device)\n",
    "                targets = targets.to(device)\n",
    "\n",
    "                predictions = model(ids, text_lengths)\n",
    "                loss = criterion(predictions, targets)\n",
    "\n",
    "                total_loss += loss.item() * ids.size(0)\n",
    "                total_correct += (predictions.round() == targets).sum().item()\n",
    "                total_labels += ids.size(0)\n",
    "\n",
    "            avg_loss = total_loss / total_labels\n",
    "            avg_acc = total_correct / total_labels\n",
    "\n",
    "            val_losses.append(avg_loss)\n",
    "            val_accuracies.append(avg_acc)\n",
    "\n",
    "            print(f'Validation Loss: {avg_loss:.3f}, Validation Accuracy: {avg_acc:.3f}')\n",
    "\n",
    "    return train_losses, val_losses, val_accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if CUDA is available and set device to GPU if it is, else CPU\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining loss function\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "# Defining the optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "\n",
    "# Moving the model and loss function to same device\n",
    "model = model.to(device)\n",
    "criterion = criterion.to(device)\n",
    "\n",
    "# Defining number of epochs\n",
    "epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses, val_losses, val_accuracies = train_model(epochs, train_loader, val_loader, model, criterion, optimizer, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Saving in Colab\n",
    "# path = \"/content/drive/My Drive/AI classification/model.pth\"\n",
    "\n",
    "# # Save the model\n",
    "# torch.save(model.state_dict(), path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading saved model - re-defining model and device so it works without running the whole notebook\n",
    "path = 'model.pth'\n",
    "model = LSTMClassifier(len(tokenizer.vocab), 100)\n",
    "model.load_state_dict(torch.load(path))\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(test_loader, model, criterion, device):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        total_loss, total_correct, total_labels = 0, 0, 0\n",
    "        all_predictions = []\n",
    "        all_targets = []\n",
    "        for batch in test_loader:\n",
    "            text_lengths, sorted_idx = batch['text_lengths'].sort(descending=True)\n",
    "            ids = batch['ids'][sorted_idx]\n",
    "            targets = batch['targets'][sorted_idx]\n",
    "\n",
    "            ids = ids.to(device)\n",
    "            text_lengths = text_lengths.to(device)\n",
    "            targets = targets.to(device)\n",
    "\n",
    "            predictions = model(ids, text_lengths)\n",
    "            loss = criterion(predictions, targets)\n",
    "\n",
    "            total_loss += loss.item() * ids.size(0)\n",
    "            total_correct += (predictions.round() == targets).sum().item()\n",
    "            total_labels += ids.size(0)\n",
    "\n",
    "            all_predictions.extend(predictions.round().cpu().numpy())\n",
    "            all_targets.extend(targets.cpu().numpy())\n",
    "\n",
    "        avg_loss = total_loss / total_labels\n",
    "        avg_acc = total_correct / total_labels\n",
    "\n",
    "        print(f'Test Loss: {avg_loss:.3f}, Test Accuracy: {avg_acc:.3f}')\n",
    "\n",
    "        class_report = classification_report(all_targets, all_predictions)\n",
    "        conf_matrix = confusion_matrix(all_targets, all_predictions)\n",
    "\n",
    "        print(class_report)\n",
    "\n",
    "    return avg_loss, avg_acc, conf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_acc, class_report, conf_matrix = evaluate_model(test_loader, model, criterion, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,7))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Truth')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "classification-project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
